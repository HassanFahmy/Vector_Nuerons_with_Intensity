{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMJkqVhgdQ3oy3tKQFicekx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HassanFahmy/Vector_Nuerons_with_Intensity/blob/main/2d_vector_nuerons_with_intensity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_graph_feature(x, k=5, idx=None, x_coord=None):\n",
        "    batch_size = x.size(0)\n",
        "    num_points = x.size(2)\n",
        "    x = x.view(batch_size, -1, num_points)\n",
        "    if idx is None:\n",
        "        if x_coord is None: # dynamic knn graph\n",
        "            idx = knn(x, k=k)\n",
        "        else:          # fixed knn graph with input point coordinates\n",
        "            idx = knn(x_coord, k=k)\n",
        "\n",
        "    idx_base = torch.arange(0, batch_size).view(-1, 1, 1)*num_points\n",
        "\n",
        "    idx = idx + idx_base\n",
        "\n",
        "    idx = idx.view(-1)\n",
        " \n",
        "    _, num_dims, _ = x.size()\n",
        "\n",
        "    x = x.transpose(2, 1).contiguous()   # (batch_size, num_points, num_dims)  -> (batch_size*num_points, num_dims) #   batch_size * num_points * k + range(0, batch_size*num_points)\n",
        "    feature = x.view(batch_size*num_points, -1)[idx, :]\n",
        "    feature = feature.view(batch_size, num_points, k, num_dims) \n",
        "    x = x.view(batch_size, num_points, 1, num_dims).repeat(1, 1, k, 1)\n",
        "    \n",
        "    feature = torch.cat((feature-x, x), dim=3).permute(0, 3, 1, 2).contiguous()\n",
        "  \n",
        "    return feature\n",
        "\n",
        "def knn(x, k):\n",
        "    inner = -2*torch.matmul(x.transpose(2, 1), x)\n",
        "    xx = torch.sum(x**2, dim=1, keepdim=True)\n",
        "    pairwise_distance = -xx - inner - xx.transpose(2, 1)\n",
        " \n",
        "    idx = pairwise_distance.topk(k=k, dim=-1)[1]   # (batch_size, num_points, k)\n",
        "    return idx"
      ],
      "metadata": {
        "id": "NKJuGPBX4Uev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oyNh1ZE21BkC"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import copy\n",
        "import math\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "EPS = 1e-6\n",
        "\n",
        "\n",
        "class VNLinear(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(VNLinear, self).__init__()\n",
        "        self.map_to_feat = nn.Linear(in_channels, out_channels, bias=False)\n",
        "    \n",
        "\n",
        "    def forward(self, x):\n",
        "        '''\n",
        "        x: point features of shape [B, N_feat, 4, N_samples, ...]\n",
        "        '''\n",
        "        x_out = self.map_to_feat(x.transpose(1,-1)).transpose(1,-1)\n",
        "        return x_out\n",
        "\n",
        "\n",
        "\n",
        "class VNLeakyReLU(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, share_nonlinearity=False, negative_slope=0.2):\n",
        "        super(VNLeakyReLU, self).__init__()\n",
        "        if share_nonlinearity == True:\n",
        "            self.map_to_dir = nn.Linear(in_channels, 1, bias=False)\n",
        "        else:\n",
        "            self.map_to_dir = nn.Linear(in_channels, in_channels, bias=False)\n",
        "        self.negative_slope = negative_slope\n",
        "        self.negative_slope = negative_slope\n",
        "    \n",
        "\n",
        "    def forward(self, x):\n",
        "        '''\n",
        "        x: point features of shape [B, N_feat, 3, N_samples, ...]\n",
        "        '''\n",
        "        d = self.map_to_dir(x.transpose(1,-1)).transpose(1,-1)\n",
        "        dotprod = (x*d).sum(2, keepdim=True)\n",
        "        mask = (dotprod >= 0).float()\n",
        "        d_norm_sq = (d*d).sum(2, keepdim=True)\n",
        "        x_out = self.negative_slope * x + (1-self.negative_slope) * (mask*x + (1-mask)*(x-(dotprod/(d_norm_sq+EPS))*d))\n",
        "        x_out = self.negative_slope * x + (1-self.negative_slope) * (mask*x + (1-mask)*(x-(dotprod/(d_norm_sq+EPS))*d))\n",
        "        return x_out\n",
        "\n",
        "\n",
        "\n",
        "class VNLinearLeakyReLU(nn.Module): ########################################\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, dim=4, share_nonlinearity=False, negative_slope=0.2):\n",
        "        super(VNLinearLeakyReLU, self).__init__()\n",
        "        self.dim = dim\n",
        "        self.negative_slope = negative_slope\n",
        "        self.negative_slope = negative_slope\n",
        "        \n",
        "        self.map_to_feat = nn.Linear(in_channels, out_channels, bias=False)\n",
        "        self.batchnorm = VNBatchNorm(out_channels, dim=dim)\n",
        "        \n",
        "        if share_nonlinearity == True:\n",
        "            self.map_to_dir = nn.Linear(in_channels, 1, bias=False)\n",
        "        else:\n",
        "            self.map_to_dir = nn.Linear(in_channels, out_channels, bias=False)\n",
        "    \n",
        "\n",
        "    def forward(self, x):\n",
        "        '''\n",
        "        x: point features of shape [B, N_feat, 3, N_samples, ...]\n",
        "        '''\n",
        "        # Linear\n",
        "        p = self.map_to_feat(x.transpose(1,-1)).transpose(1,-1)\n",
        "        \n",
        "        # BatchNorm\n",
        "        p = self.batchnorm(p)\n",
        "        # LeakyReLU\n",
        "        d = self.map_to_dir(x.transpose(1,-1)).transpose(1,-1)\n",
        "        dotprod = (p*d).sum(2, keepdims=True)\n",
        "        mask = (dotprod >= 0).float()\n",
        "        d_norm_sq = (d*d).sum(2, keepdims=True)\n",
        "        x_out = self.negative_slope * p + (1-self.negative_slope) * (mask*p + (1-mask)*(p-(dotprod/(d_norm_sq+EPS))*d))\n",
        "        x_out = self.negative_slope * p + (1-self.negative_slope) * (mask*p + (1-mask)*(p-(dotprod/(d_norm_sq+EPS))*d))\n",
        "        return x_out\n",
        "\n",
        "\n",
        "\n",
        "class VNLinearAndLeakyReLU(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, dim=5, share_nonlinearity=False, use_batchnorm='norm', negative_slope=0.2):\n",
        "        super(VNLinearLeakyReLU, self).__init__()\n",
        "        self.dim = dim\n",
        "        self.share_nonlinearity = share_nonlinearity\n",
        "        self.use_batchnorm = use_batchnorm\n",
        "        self.negative_slope = negative_slope\n",
        "        self.negative_slope = negative_slope\n",
        "        \n",
        "        self.linear = VNLinear(in_channels, out_channels)\n",
        "        self.leaky_relu = VNLeakyReLU(out_channels, share_nonlinearity=share_nonlinearity, negative_slope=negative_slope)\n",
        "        self.leaky_relu = VNLeakyReLU(out_channels, share_nonlinearity=share_nonlinearity, negative_slope=negative_slope)\n",
        "        \n",
        "        # BatchNorm\n",
        "        self.use_batchnorm = use_batchnorm\n",
        "        if use_batchnorm != 'none':\n",
        "            self.batchnorm = VNBatchNorm(out_channels, dim=dim, mode=use_batchnorm)\n",
        "    \n",
        "\n",
        "    def forward(self, x):\n",
        "        '''\n",
        "        x: point features of shape [B, N_feat, 3, N_samples, ...]\n",
        "        '''\n",
        "        # Conv\n",
        "        x = self.linear(x)\n",
        "        # InstanceNorm\n",
        "        if self.use_batchnorm != 'none':\n",
        "            x = self.batchnorm(x)\n",
        "        # LeakyReLU\n",
        "        x_out = self.leaky_relu(x)\n",
        "        return x_out\n",
        "\n",
        "\n",
        "\n",
        "class VNBatchNorm(nn.Module):\n",
        "\n",
        "    def __init__(self, num_features, dim):\n",
        "        super(VNBatchNorm, self).__init__()\n",
        "        self.dim = dim\n",
        "        if dim == 3 or dim == 4:\n",
        "            self.bn = nn.BatchNorm1d(num_features)\n",
        "        elif dim == 5:\n",
        "            self.bn = nn.BatchNorm2d(num_features)\n",
        "    \n",
        "\n",
        "    def forward(self, x):\n",
        "        '''\n",
        "        x: point features of shape [B, N_feat, 3, N_samples, ...]\n",
        "        '''\n",
        "        # norm = torch.sqrt((x*x).sum(2))\n",
        "        norm = torch.norm(x, dim=2) + EPS\n",
        "        norm_bn = self.bn(norm)\n",
        "        norm = norm.unsqueeze(2)\n",
        "        norm_bn = norm_bn.unsqueeze(2)\n",
        "        x = x / norm * norm_bn\n",
        "        \n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "class VNMaxPool(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super(VNMaxPool, self).__init__()\n",
        "        self.map_to_dir = nn.Linear(in_channels, in_channels, bias=False)\n",
        "    \n",
        "\n",
        "    def forward(self, x):\n",
        "        '''\n",
        "        x: point features of shape [B, N_feat, 3, N_samples, ...]\n",
        "        '''\n",
        "        d = self.map_to_dir(x.transpose(1,-1)).transpose(1,-1)\n",
        "        dotprod = (x*d).sum(2, keepdims=True)\n",
        "        idx = dotprod.max(dim=-1, keepdim=False)[1]\n",
        "        index_tuple = torch.meshgrid([torch.arange(j) for j in x.size()[:-1]]) + (idx,)\n",
        "        x_max = x[index_tuple]\n",
        "        return x_max\n",
        "\n",
        "\n",
        "def mean_pool(x, dim=-1, keepdim=False):\n",
        "    return x.mean(dim=dim, keepdim=keepdim)\n",
        "\n",
        "\n",
        "\n",
        "class VNStdFeature(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, dim=3, normalize_frame=False, share_nonlinearity=False, negative_slope=0.2):\n",
        "        super(VNStdFeature, self).__init__()\n",
        "        self.dim = dim\n",
        "        self.normalize_frame = normalize_frame\n",
        "        \n",
        "        self.vn1 = VNLinearLeakyReLU(in_channels, in_channels//2, dim=dim, share_nonlinearity=share_nonlinearity, negative_slope=negative_slope)\n",
        "        self.vn2 = VNLinearLeakyReLU(in_channels//2, in_channels//4, dim=dim, share_nonlinearity=share_nonlinearity, negative_slope=negative_slope)\n",
        "        if normalize_frame:\n",
        "            self.vn_lin = nn.Linear(in_channels//4, 2, bias=False)\n",
        "        else:\n",
        "            self.vn_lin = nn.Linear(in_channels//4, 3, bias=False)\n",
        "    \n",
        "\n",
        "    def forward(self, x):\n",
        "        '''\n",
        "        x: point features of shape [B, N_feat, 3, N_samples, ...]\n",
        "        '''\n",
        "        z0 = x\n",
        "        z0 = self.vn1(z0)\n",
        "        z0 = self.vn2(z0)\n",
        "        z0 = self.vn_lin(z0.transpose(1, -1)).transpose(1, -1)\n",
        "\n",
        "        \n",
        "        if self.normalize_frame:\n",
        "            # make z0 orthogonal. u2 = v2 - proj_u1(v2)\n",
        "            v1 = z0[:,0,:]\n",
        "            #u1 = F.normalize(v1, dim=1)\n",
        "            v1_norm = torch.sqrt((v1*v1).sum(1, keepdims=True))\n",
        "            u1 = v1 / (v1_norm+EPS)\n",
        "            v2 = z0[:,1,:]\n",
        "            v2 = v2 - (v2*u1).sum(1, keepdims=True)*u1\n",
        "            #u2 = F.normalize(u2, dim=1)\n",
        "            v2_norm = torch.sqrt((v2*v2).sum(1, keepdims=True))\n",
        "            u2 = v2 / (v2_norm+EPS)\n",
        "\n",
        "            # compute the cross product of the two output vectors        \n",
        "            u3 = torch.cross(u1, u2)\n",
        "            z0 = torch.stack([u1, u2, u3], dim=1).transpose(1, 2)\n",
        "        else:\n",
        "            z0 = z0.transpose(1, 2)\n",
        "        if self.dim == 4:\n",
        "            x_std = torch.einsum('bijm,bjkm->bikm', x, z0)\n",
        "        elif self.dim == 3:\n",
        "            x_std = torch.einsum('bij,bjk->bik', x, z0)\n",
        "        elif self.dim == 5:\n",
        "            x_std = torch.einsum('bijmn,bjkmn->bikmn', x, z0)\n",
        "        \n",
        "        return x_std, z0\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.utils.data\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class get_model(nn.Module):\n",
        "\n",
        "    def __init__(self, num_class=10, normal_channel=False):\n",
        "        super(get_model, self).__init__()\n",
        "        self.n_knn = 5 #args.n_knn\n",
        "        \n",
        "        self.conv1 = VNLinearLeakyReLU(1, 64//3)\n",
        "        self.conv2 = VNLinearLeakyReLU(64//3, 64//3) \n",
        "        self.conv3 = VNLinearLeakyReLU(64//3, 128//3)\n",
        "        self.conv4 = VNLinearLeakyReLU(128//3, 256//3)\n",
        "        self.conv5 = VNLinearLeakyReLU(256//3+128//3+64//3+64//3, 1024//3, dim=4, share_nonlinearity=True)\n",
        "        \n",
        "        self.std_feature = VNStdFeature(1024//3*2, dim=3, normalize_frame=False)\n",
        "        self.linear1 = nn.Linear((1024//3)*4, 512)\n",
        "        \n",
        "        self.bn1 = nn.BatchNorm1d(512)\n",
        "        self.dp1 = nn.Dropout(p=0.5)\n",
        "        self.linear2 = nn.Linear(512, 256)\n",
        "        self.bn2 = nn.BatchNorm1d(256)\n",
        "        self.dp2 = nn.Dropout(p=0.5)\n",
        "        self.linear3 = nn.Linear(256, num_class)\n",
        "        \n",
        "\n",
        "        self.pool1 = VNMaxPool(64//3)\n",
        "        self.pool2 = VNMaxPool(64//3)\n",
        "        self.pool3 = VNMaxPool(128//3)\n",
        "        self.pool4 = VNMaxPool(256//3)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "        #x = x.unsqueeze(1)\n",
        "        x = self.conv1(x)\n",
        "        x1 = self.pool1(x)\n",
        "        \n",
        "        x = self.conv2(x)\n",
        "        x2 = self.pool2(x)\n",
        "        \n",
        "        x = self.conv3(x)\n",
        "        x3 = self.pool3(x)\n",
        "        \n",
        "        x = self.conv4(x)\n",
        "        x4 = self.pool4(x)\n",
        "        \n",
        "        x = torch.cat((x1, x2, x3, x4), dim=1)\n",
        "        x = self.conv5(x)\n",
        "        \n",
        "        num_points = x.size(-1)\n",
        "        x_mean = x.mean(dim=-1, keepdim=True).expand(x.size())\n",
        "        x = torch.cat((x, x_mean), 1)\n",
        "        x, trans = self.std_feature(x)\n",
        "        #swap x with trans?\n",
        "        #x = x.view(batch_size, -1, num_points)\n",
        "        \n",
        "        x1 = F.adaptive_max_pool1d(x, 1).view(batch_size, -1)\n",
        "        x2 = F.adaptive_avg_pool1d(x, 1).view(batch_size, -1)\n",
        "        x = torch.cat((x1, x2), 1)\n",
        "        x = F.leaky_relu(self.bn1(self.linear1(x)), negative_slope=0.2)\n",
        "        x = self.dp1(x)\n",
        "        x = F.leaky_relu(self.bn2(self.linear2(x)), negative_slope=0.2)\n",
        "        x = self.dp2(x)\n",
        "        x = self.linear3(x)\n",
        "        \n",
        "        trans_feat = None\n",
        "        return x, trans_feat\n",
        "\n",
        "\n",
        "\n",
        "class get_loss(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(get_loss, self).__init__()\n",
        "\n",
        "\n",
        "    def forward(self, pred, target, trans_feat, smoothing=True):\n",
        "        ''' Calculate cross entropy loss, apply label smoothing if needed. '''\n",
        "\n",
        "        target = target.contiguous().view(-1)\n",
        "\n",
        "        if smoothing:\n",
        "            eps = 0.2\n",
        "            n_class = pred.size(1)\n",
        "\n",
        "            one_hot = torch.zeros_like(pred).scatter(1, target.view(-1, 1), 1)\n",
        "            one_hot = one_hot * (1 - eps) + (1 - one_hot) * eps / (n_class - 1)\n",
        "            log_prb = F.log_softmax(pred, dim=1)\n",
        "\n",
        "            loss = -(one_hot * log_prb).sum(dim=1).mean()\n",
        "        else:\n",
        "            loss = F.cross_entropy(pred, target, reduction='mean')\n",
        "            \n",
        "        return loss\n"
      ],
      "metadata": {
        "id": "upSDx1uPteQh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = get_model()\n",
        "criterion = get_loss()\n",
        "optimizer = torch.optim.SGD(\n",
        "            classifier.parameters(),\n",
        "            lr=0.01,\n",
        "            momentum=0.9,\n",
        "            weight_decay=1e-4\n",
        "        )\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.7)\n",
        "global_epoch = 0\n",
        "global_step = 0\n",
        "best_instance_acc = 0.0\n",
        "best_class_acc = 0.0\n",
        "mean_correct = []"
      ],
      "metadata": {
        "id": "_nNG-fS95Lcw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"x = torch.rand(5,40,3)\n",
        "emb ,feat = classifier(x)\n",
        "print (emb.shape)\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "CffjPUPuM5Bc",
        "outputId": "34e76f2f-9310-4b11-e038-ecb9a1792b17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'x = torch.rand(5,40,3)\\nemb ,feat = classifier(x)\\nprint (emb.shape)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ToPC(object):\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        ret = torch.tensor([[[i/sample.shape[1],j/sample.shape[2],sample[b][i][j]]for i in range(sample.shape[1])for j in range(sample.shape[2]) ]for b in range(sample.shape[0])])\n",
        "        return ret"
      ],
      "metadata": {
        "id": "LKImiCbw2kfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "  torchvision.datasets.MNIST('/files/', train=True, download=True,\n",
        "                             transform=torchvision.transforms.Compose([\n",
        "                               torchvision.transforms.ToTensor(),\n",
        "                               torchvision.transforms.RandomRotation((-90,90)),\n",
        "                               torchvision.transforms.Normalize(\n",
        "                                 (0.1307,), (0.3081,)),\n",
        "                               #ToPC(),\n",
        "                             ])),\n",
        "  batch_size=4, shuffle=True)\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(\n",
        "  torchvision.datasets.MNIST('/files/', train=False, download=True,\n",
        "                             transform=torchvision.transforms.Compose([\n",
        "                               torchvision.transforms.ToTensor(),\n",
        "                               torchvision.transforms.Normalize(\n",
        "                                 (0.1307,), (0.3081,))\n",
        "                             ])),\n",
        "  batch_size=1, shuffle=True)\n",
        "\n",
        "\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = next(dataiter)\n",
        "print (\"images\", images.shape, \"labels:\", labels)\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "print(images[0][0][15])\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = next(dataiter)\n",
        "print(\"images shape\", images.shape)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "hfoYdwBEzf9E",
        "outputId": "2f601635-5aeb-4508-d6b5-c8807da6c6c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "images torch.Size([4, 1, 28, 28]) labels: tensor([7, 5, 3, 1])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.3478,\n",
            "         0.3904,  2.6815,  2.7960,  2.8088,  2.8088,  1.6123, -0.2587, -0.4242,\n",
            "        -0.4242,  1.9178,  2.7960,  1.3450, -0.4242, -0.4242, -0.4242, -0.4242,\n",
            "        -0.4242, -0.4242, -0.4242, -0.4242])\n",
            "images shape torch.Size([4, 1, 28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from random import randrange\n",
        "from math import sin, cos\n",
        "for epoch in range(2):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "       \n",
        "        outputs,feats = classifier(inputs)       \n",
        "        loss = criterion(outputs, labels, feats)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 200 == 0:    # print every 200 mini-batches\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
        "            print(outputs)\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XJJLziBtz0-8",
        "outputId": "b4d89ab1-1a20-4aa7-869b-67027822288d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,     1] loss: 0.001\n",
            "tensor([[ 0.0932,  0.0666, -0.6040, -0.1777,  0.6754,  0.3679,  0.0790,  0.8604,\n",
            "          0.0214, -0.3146],\n",
            "        [ 0.0396,  0.2205, -0.1738,  0.2923,  0.6137, -0.1601,  0.1954,  0.6083,\n",
            "          0.2167,  0.2731],\n",
            "        [-0.0983, -0.2786, -0.8190,  0.3254,  0.4119,  0.4605,  0.6856,  0.3469,\n",
            "         -1.0678, -0.3431],\n",
            "        [-0.4706, -0.4240, -1.1302,  0.2684, -1.4012,  0.8349,  1.0387, -0.9214,\n",
            "          0.5791, -0.8731],\n",
            "        [-0.2688, -0.2008, -0.6936, -0.3677,  0.0267,  0.3742, -0.0874,  0.0418,\n",
            "         -0.5375,  0.0495],\n",
            "        [-0.3855, -0.0131, -0.2314,  0.5344,  0.5044,  0.0930, -0.3486, -0.6947,\n",
            "         -0.2364,  0.6783],\n",
            "        [ 0.2440,  0.1381, -0.4344, -0.1440, -0.0758, -0.6289,  0.9615,  0.1989,\n",
            "         -0.2195,  0.4631],\n",
            "        [ 0.4742,  0.7724,  0.1168, -0.2925, -0.7670,  0.5278,  0.0454, -0.2705,\n",
            "         -0.3141,  0.3586],\n",
            "        [-0.4260,  0.6169,  0.0272, -0.0041,  0.1606, -0.2463,  0.0125, -0.1981,\n",
            "         -0.1180, -0.1100],\n",
            "        [ 0.2501,  0.2125,  0.0256, -0.2555, -0.1990, -0.1107,  0.2837,  0.1042,\n",
            "         -0.0887,  0.2783],\n",
            "        [ 0.0741, -0.0086, -0.0957,  0.0539,  0.2993,  0.5473, -0.0656, -0.2727,\n",
            "          0.5587,  0.0895],\n",
            "        [ 0.2139,  0.9183,  0.2255, -2.1068, -0.1743,  0.2771,  0.8822,  0.6119,\n",
            "         -0.1983,  0.3934],\n",
            "        [ 0.8559,  0.7473, -0.1861,  0.5838,  0.1117,  0.5295, -0.8732, -0.8223,\n",
            "          0.7904, -0.6307],\n",
            "        [-0.6955, -0.4531,  0.2730, -0.4074, -0.2304, -0.1774,  0.0136, -0.1523,\n",
            "         -0.6513,  0.0451],\n",
            "        [ 0.1445, -0.2580, -0.3222, -0.1393,  0.2895,  0.8362, -1.4281,  0.0552,\n",
            "          0.7038, -0.9623],\n",
            "        [-0.4974, -0.3798, -0.1939, -0.4317, -0.2902, -0.3417, -0.1575, -0.0466,\n",
            "          0.1516,  0.3253],\n",
            "        [-0.1026, -0.1523, -0.3434, -0.4290, -0.1984, -0.2616,  0.1329, -0.5263,\n",
            "          0.2352,  0.1298],\n",
            "        [-0.0407, -0.1697, -0.1479,  0.1753,  0.0567, -0.5080,  0.9386, -0.4202,\n",
            "         -0.7428, -0.6286],\n",
            "        [ 1.4045, -0.2177,  1.1263, -1.1713, -1.3032, -0.5575,  0.8526,  1.8542,\n",
            "          0.5800,  0.3974],\n",
            "        [ 0.2553,  0.2521,  0.1465, -0.1063, -0.0743,  0.2763, -0.1427,  0.1098,\n",
            "          0.1440, -0.0460]], grad_fn=<AddmmBackward0>)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-45e4071ef884>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch3d"
      ],
      "metadata": {
        "id": "8zO6TIWSXNbi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch3d.transforms import RotateAxisAngle, Rotate, random_rotations\n",
        "x = torch.rand(10,40,3)\n",
        "emb ,feat = classifier(x)\n",
        "trot = RotateAxisAngle(angle=90, axis=\"Z\", degrees=True)\n",
        "x2 = trot.transform_points(x)\n",
        "emb2 ,feat = classifier(x2)\n",
        "inemb1 = trot.transform_points(emb)\n",
        "print (emb2-inemb1)\n",
        "print(emb2)"
      ],
      "metadata": {
        "id": "r-27uflUXkuP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch3d.transforms import RotateAxisAngle, Rotate, random_rotations\n",
        "\n",
        "rot = 'so3'\n",
        "num_epochs = 2\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "        print('Epoch %d (%d/%s):' % (global_epoch + 1, epoch + 1, args.epoch))\n",
        "\n",
        "        scheduler.step()\n",
        "        for batch_id, data in tqdm(enumerate(trainDataLoader, 0), total=len(trainDataLoader), smoothing=0.9):\n",
        "            points, target = data\n",
        "            \n",
        "            trot = None\n",
        "            if rot == 'z':\n",
        "                trot = RotateAxisAngle(angle=torch.rand(points.shape[0])*360, axis=\"Z\", degrees=True)\n",
        "                trot = RotateAxisAngle(angle=torch.rand(points.shape[0])*360, axis=\"Z\", degrees=True)\n",
        "            elif rot == 'so3':\n",
        "                trot = Rotate(R=random_rotations(points.shape[0]))\n",
        "                trot = Rotate(R=random_rotations(points.shape[0]))\n",
        "            if trot is not None:\n",
        "                points = trot.transform_points(points)\n",
        "            \n",
        "            points = points.data.numpy()\n",
        "            points = provider.random_point_dropout(points)\n",
        "            points[:,:, 0:3] = provider.random_scale_point_cloud(points[:,:, 0:3])\n",
        "            points[:,:, 0:3] = provider.shift_point_cloud(points[:,:, 0:3])\n",
        "            points = torch.Tensor(points)\n",
        "            target = target[:, 0]\n",
        "\n",
        "            points = points.transpose(2, 1)\n",
        "            points, target = points.cuda(), target.cuda()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            classifier = classifier.train()\n",
        "            pred, trans_feat = classifier(points)\n",
        "            loss = criterion(pred, target.long(), trans_feat)\n",
        "            pred_choice = pred.data.max(1)[1]\n",
        "            correct = pred_choice.eq(target.long().data).cpu().sum()\n",
        "            mean_correct.append(correct.item() / float(points.size()[0]))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            global_step += 1\n",
        "\n",
        "        train_instance_acc = np.mean(mean_correct)\n",
        "        print('Train Instance Accuracy: %f' % train_instance_acc)\n",
        "\n",
        "\n",
        "        with torch.no_grad():\n",
        "            instance_acc, class_acc = test(classifier.eval(), testDataLoader)\n",
        "\n",
        "            if (instance_acc >= best_instance_acc):\n",
        "                best_instance_acc = instance_acc\n",
        "                best_epoch = epoch + 1\n",
        "\n",
        "            if (class_acc >= best_class_acc):\n",
        "                best_class_acc = class_acc\n",
        "            log_string('Test Instance Accuracy: %f, Class Accuracy: %f'% (instance_acc, class_acc))\n",
        "            log_string('Best Instance Accuracy: %f, Class Accuracy: %f'% (best_instance_acc, best_class_acc))\n",
        "\n",
        "            if (instance_acc >= best_instance_acc):\n",
        "                logger.info('Save model...')\n",
        "                savepath = str(checkpoints_dir) + '/best_model.pth'\n",
        "                log_string('Saving at %s'% savepath)\n",
        "                state = {\n",
        "                    'epoch': best_epoch,\n",
        "                    'instance_acc': instance_acc,\n",
        "                    'class_acc': class_acc,\n",
        "                    'model_state_dict': classifier.state_dict(),\n",
        "                    'optimizer_state_dict': optimizer.state_dict(),\n",
        "                }\n",
        "                torch.save(state, savepath)\n",
        "            global_epoch += 1\n"
      ],
      "metadata": {
        "id": "KzhpP2ybPJ1_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}